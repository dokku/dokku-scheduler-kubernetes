#!/usr/bin/env bash
source "$PLUGIN_CORE_AVAILABLE_PATH/common/functions"
source "$PLUGIN_CORE_AVAILABLE_PATH/common/property-functions"
source "$PLUGIN_AVAILABLE_PATH/config/functions"
source "$PLUGIN_AVAILABLE_PATH/domains/functions"
set -eo pipefail
[[ $DOKKU_TRACE ]] && set -x

cmd-scheduler-kubernetes-rolling-update() {
  declare desc="force a rolling update"
  declare cmd="scheduler-kubernetes:rolling-update" argv=("$@")
  [[ ${argv[0]} == "$cmd" ]] && shift 1
  declare APP="$1"

  verify_app_name "$APP"
  local DOKKU_SCHEDULER=$(get_app_scheduler "$APP")
  if [[ "$DOKKU_SCHEDULER" != "kubernetes" ]]; then
    dokku_log_fail "Scheduler for $APP is set to $DOKKU_SCHEDULER"
    return 1
  fi

  export KUBECONFIG="${DOKKU_ROOT}/.kube/config"
  export KUBEDOG_KUBE_CONFIG="${DOKKU_ROOT}/.kube/config"
  KUBE_ARGS=()
  NAMESPACE="$(fn-plugin-property-get "scheduler-kubernetes" "$APP" "namespace" "default")"
  KUBE_ARGS+=("--namespace=$NAMESPACE")
  fn-scheduler-kubernetes-ensure-namespace "$NAMESPACE" >/dev/null

  dokku_log_info1 "Triggering rolling-update for $APP"
  while read -r line || [[ -n "$line" ]]; do
    [[ "$line" =~ ^#.* ]] && continue
    line="$(strip_inline_comments "$line")"
    PROC_TYPE=${line%%=*}

    "${DOKKU_LIB_ROOT}/data/scheduler-kubernetes/kubectl" "${KUBE_ARGS[@]}" patch deployment "${APP}-${PROC_TYPE}" --patch "{\"spec\":{\"template\":{\"metadata\":{\"labels\":{\"dokku.com/rolling-update-time\":\"$(date -u "+%Y-%m-%d-%H-%M-%S")\"}}}}}" | sed "s/^/       /"
  done < <(plugin trigger ps-current-scale "$APP")
}

cmd-scheduler-kubernetes-report() {
  declare desc="displays a scheduler-kubernetes report for one or more apps"
  declare cmd="scheduler-kubernetes:report"
  local INSTALLED_APPS=$(dokku_apps)
  local APP="$2" INFO_FLAG="$3"

  if [[ -n "$APP" ]] && [[ "$APP" == --* ]]; then
    INFO_FLAG="$APP"
    APP=""
  fi

  if [[ -z "$APP" ]] && [[ -z "$INFO_FLAG" ]]; then
    INFO_FLAG="true"
  fi

  if [[ -z "$APP" ]]; then
    for app in $INSTALLED_APPS; do
      cmd-scheduler-kubernetes-report-single "$app" "$INFO_FLAG" | tee || true
    done
  else
    cmd-scheduler-kubernetes-report-single "$APP" "$INFO_FLAG"
  fi
}

cmd-scheduler-kubernetes-report-single() {
  declare APP="$1" INFO_FLAG="$2"
  if [[ "$INFO_FLAG" == "true" ]]; then
    INFO_FLAG=""
  fi
  verify_app_name "$APP"
  local flag_map=(
    "--scheduler-kubernetes-cert-manager-enabled: $(fn-plugin-property-get "scheduler-kubernetes" "$APP" "cert-manager-enabled" "")"
    "--scheduler-kubernetes-imagePullSecrets: $(fn-plugin-property-get "scheduler-kubernetes" "$APP" "imagePullSecrets" "")"
    "--scheduler-kubernetes-ingress-enabled: $(fn-plugin-property-get "scheduler-kubernetes" "$APP" "ingress-enabled" "false")"
    "--scheduler-kubernetes-namespace: $(fn-plugin-property-get "scheduler-kubernetes" "$APP" "namespace" "")"
    "--scheduler-kubernetes-pod-max-unavailable: $(fn-plugin-property-get "scheduler-kubernetes" "$APP" "pod-max-unavailable" "")"
    "--scheduler-kubernetes-pod-min-available: $(fn-plugin-property-get "scheduler-kubernetes" "$APP" "pod-min-available" "")"
    "--scheduler-kubernetes-service-process-types: $(fn-plugin-property-get "scheduler-kubernetes" "$APP" "service-process-types" "")"
  )

  if [[ -z "$INFO_FLAG" ]]; then
    dokku_log_info2_quiet "${APP} scheduler-kubernetes information"
    for flag in "${flag_map[@]}"; do
      key="$(echo "${flag#--}" | cut -f1 -d' ' | tr - ' ')"
      dokku_log_verbose "$(printf "%-30s %-25s" "${key^}" "${flag#*: }")"
    done
  else
    local match=false
    local value_exists=false
    for flag in "${flag_map[@]}"; do
      valid_flags="${valid_flags} $(echo "$flag" | cut -d':' -f1)"
      if [[ "$flag" == "${INFO_FLAG}:"* ]]; then
        value=${flag#*: }
        size="${#value}"
        if [[ "$size" -ne 0 ]]; then
          echo "$value" && match=true && value_exists=true
        else
          match=true
        fi
      fi
    done
    [[ "$match" == "true" ]] || dokku_log_fail "Invalid flag passed, valid flags:${valid_flags}"
    [[ "$value_exists" == "true" ]] || echo ""
  fi
}

scheduler_docker_local_help_content_func() {
  declare desc="return scheduler-kubernetes plugin help content"
  cat <<help_content
    scheduler-kubernetes:autoscale-apply <app> <proc_type> <key> <value>, Apply autoscale settings for an app/proc-type combination
    scheduler-kubernetes:autoscale-rule-add <app> <proc_type> <key> <value>, Add an autoscale rule for an app/proc-type combination
    scheduler-kubernetes:autoscale-rule-list <app> <proc_type> <key> <value>, List autoscale rules for an app/proc-type combination
    scheduler-kubernetes:autoscale-rule-remove <app> <proc_type> <key> <value>, Remove an autoscale rule for an app/proc-type combination
    scheduler-kubernetes:autoscale-set <app> <proc_type> <key> <value>, Set or clear autoscale settings for an app/proc-type combination
    scheduler-kubernetes:deployment-annotations-set <app> <key> <value>, Set or clear a scheduler-kubernetes deployment annotation for an app
    scheduler-kubernetes:pod-annotations-set <app> <key> <value>, Set or clear a scheduler-kubernetes pod annotation for an app
    scheduler-kubernetes:ingress-annotations-set <namespace> <key> (<value>), Set or clear a scheduler-kubernetes ingress annotation for a namespace
    scheduler-kubernetes:report [<app>] [<flag>], Displays a scheduler-kubernetes report for one or more apps
    scheduler-kubernetes:rolling-update <app>, Force a rolling update
    scheduler-kubernetes:service-annotations-set <app> <key> <value>, Set or clear a scheduler-kubernetes service annotation for an app
    scheduler-kubernetes:set <app> <property> (<value>), Set or clear a scheduler-kubernetes property for an app
    scheduler-kubernetes:show-manifest <app> <proc_type> (<manifest_type>), Display the deployment or service manifest for a given app/process type combination
    scheduler-kubernetes:add-pvc <name> <size> --access-mode <mode> --namespace <namespace> --storage-class-name <class-name>, Adds a Persistent Volume Claim (PVC)
    scheduler-kubernetes:remove-pvc <name> --namespace <namespace>, Remove Persistent Volume Claim in Namespace
    scheduler-kubernetes:list-pvc (<namespace>), Display Persistent Volume Claims by Namespace
    scheduler-kubernetes:mount <app> <pvc_name> </container/path>, Mount a Volume to Container Path for an app
    scheduler-kubernetes:unmount <app> <pvc_name> </container/path>, Unmount a Volume from an app
    scheduler-kubernetes:unmount-all <app>, Unmount all Volumes from an app
    scheduler-kubernetes:list-mount <app>, List Mounted Volumes for an app
help_content
}

cmd-scheduler-kubernetes-help() {
  if [[ $1 == "scheduler-kubernetes:help" ]]; then
    echo -e 'Usage: dokku scheduler-kubernetes[:COMMAND]'
    echo ''
    echo 'Manages the scheduler-kubernetes integration for an app.'
    echo ''
    echo 'Additional commands:'
    scheduler_docker_local_help_content_func | sort | column -c2 -t -s,
    echo ''
  elif [[ $(ps -o command= $PPID) == *"--all"* ]]; then
    scheduler_docker_local_help_content_func
  else
    cat <<help_desc
    scheduler-kubernetes, Manages the scheduler-kubernetes integration for an app
help_desc
  fi
}

fn-scheduler-kubernetes-add-cert-manager() {
  declare INGRESS_FILE="$1" CERT_MANAGER_DOMAINS="${@:2}"
  local CERT_MANAGER_TLS_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/cert-manager-tls.json.sigil"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  jq --argjson tls "$(sigil -f "$CERT_MANAGER_TLS_TEMPLATE")" '.spec.tls += $tls' <"$INGRESS_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$INGRESS_FILE"

  for domain in ${CERT_MANAGER_DOMAINS[@]}; do
    DOMAIN="$domain" jq '.spec.tls[0].hosts += [env.DOMAIN]' <"$INGRESS_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$INGRESS_FILE"
  done

  jq -M '.metadata.annotations["cert-manager.io/cluster-issuer"] = "letsencrypt-prod"' <"$INGRESS_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$INGRESS_FILE"
}

fn-scheduler-kubernetes-add-ingress-rule() {
  declare APP="$1" PROC_TYPE="$2" PORT="$3" DOMAIN="$4" INGRESS_FILE="$5"
  local RULE_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/ingress-rule.json.sigil"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  local SIGIL_PARAMS=(APP="$APP" PROCESS_TYPE="$PROC_TYPE" PORT="$PORT" DOMAIN="$DOMAIN")
  jq --argjson rule "$(sigil -f "$RULE_TEMPLATE" "${SIGIL_PARAMS[@]}")" '.spec.rules += [$rule]' <"$INGRESS_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$INGRESS_FILE"
}

fn-scheduler-kubernetes-autoscale-in-use() {
  declare desc="checks if the horizontal pod autoscaler should be used for an app/proc-type combination"
  declare APP="$1" PROC_TYPE="$2"

  MAX_REPLICAS="$(fn-plugin-property-get "scheduler-kubernetes" "$APP" "autoscale.$PROC_TYPE.max-replicas" "")"
  MIN_REPLICAS="$(fn-plugin-property-get "scheduler-kubernetes" "$APP" "autoscale.$PROC_TYPE.min-replicas" "")"
  if [[ -z "$MAX_REPLICAS" ]] || [[ -z "$MIN_REPLICAS" ]]; then
    return 1
  fi

  RULES="$(fn-plugin-property-list-get "scheduler-kubernetes" "$APP" "autoscale.$PROC_TYPE")"
  if [[ -z "$RULES" ]]; then
    return 1
  fi
}

fn-scheduler-kubernetes-autoscale-apply() {
  declare desc="applies horizontal pod autoscaler rules"
  declare APP="$1" PROC_TYPE="$2"

  export KUBECONFIG="${DOKKU_ROOT}/.kube/config"
  export KUBEDOG_KUBE_CONFIG="${DOKKU_ROOT}/.kube/config"
  KUBE_ARGS=()
  NAMESPACE="$(fn-plugin-property-get "scheduler-kubernetes" "$APP" "namespace" "default")"
  KUBE_ARGS+=("--namespace=$NAMESPACE")
  fn-scheduler-kubernetes-ensure-namespace "$NAMESPACE" >/dev/null

  RULES="$(fn-plugin-property-list-get "scheduler-kubernetes" "$APP" "autoscale.$PROC_TYPE")"
  if [[ -z "$RULES" ]]; then
    dokku_log_warn "No rules specified for $APP.$PROC_TYPE"
    "${DOKKU_LIB_ROOT}/data/scheduler-kubernetes/kubectl" "${KUBE_ARGS[@]}" delete hpa -l app-process-type="$APP-$PROC_TYPE"
    return
  fi

  local INGRESS_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/horizontal-pod-autoscaler.json.sigil"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  MAX_REPLICAS="$(fn-plugin-property-get "scheduler-kubernetes" "$APP" "autoscale.$PROC_TYPE.max-replicas" "")"
  MIN_REPLICAS="$(fn-plugin-property-get "scheduler-kubernetes" "$APP" "autoscale.$PROC_TYPE.min-replicas" "")"
  if [[ -z "$MAX_REPLICAS" ]] || [[ -z "$MIN_REPLICAS" ]]; then
    dokku_log_warn "Must specify max-replicas and min-replicas for $APP.$PROC_TYPE"
    return
  fi

  local SIGIL_PARAMS=(APP="$APP" MAX_REPLICAS="$MAX_REPLICAS" MIN_REPLICAS="$MIN_REPLICAS" PROCESS_TYPE="$PROC_TYPE")
  sigil -f "$INGRESS_TEMPLATE" "${SIGIL_PARAMS[@]}" | cat -s >"$TMP_FILE"

  for RULE in ${RULES[@]}; do
    fn-scheduler-kubernetes-autoscale-add-hpa-rule "$RULE" "$TMP_FILE"
  done

  "${DOKKU_LIB_ROOT}/data/scheduler-kubernetes/kubectl" apply -f "$TMP_FILE" | sed "s/^/       /"
}

fn-scheduler-kubernetes-autoscale-add-hpa-rule() {
  declare RULE="$1" HPA_FILE="$2"
  local METRIC_TYPE="$(echo "$RULE" | cut -d':' -f1)"
  local TARGET_NAME="$(echo "$RULE" | cut -d':' -f2)"
  local TARGET_TYPE="$(echo "$RULE" | cut -d':' -f3)"
  local TARGET_VALUE="$(echo "$RULE" | cut -d':' -f4)"
  local TARGET_EXTRA="$(echo "$RULE" | cut -d':' -f5)"

  local RULE_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/horizontal-pod-autoscaler-metric-${METRIC_TYPE}.json.sigil"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  if [[ "$METRIC_TYPE" == "external" ]] && [[ -n "$TARGET_EXTRA" ]]; then
    RULE_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/horizontal-pod-autoscaler-metric-${METRIC_TYPE}-selector.json.sigil"
  fi

  if [[ "$METRIC_TYPE" == "ingress" ]] && [[ -z "$TARGET_EXTRA" ]]; then
    TARGET_EXTRA="app-ingress"
  fi

  TARGET_TYPE_KEY="value"
  if [[ "$TARGET_TYPE" == "AverageValue" ]]; then
    TARGET_TYPE_KEY="averageValue"
  elif [[ "$TARGET_TYPE" == "Utilization" ]]; then
    TARGET_TYPE_KEY="averageUtilization"
  fi

  local SIGIL_PARAMS=(METRIC_TYPE="$METRIC_TYPE" TARGET_NAME="$TARGET_NAME" TARGET_TYPE="$TARGET_TYPE" TARGET_VALUE="$TARGET_VALUE" TARGET_EXTRA="$TARGET_EXTRA" TARGET_TYPE_KEY="$TARGET_TYPE_KEY")
  jq --argjson metric "$(sigil -f "$RULE_TEMPLATE" "${SIGIL_PARAMS[@]}")" '.spec.metrics += [$metric]' <"$HPA_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$HPA_FILE"
}

fn-scheduler-kubernetes-autoscale-rule-validate() {
  declare desc="validate an autoscale rule"
  declare RULE="$1"
  local METRIC_TYPE TARGET_NAME TARGET_TYPE TARGET_VALUE

  METRIC_TYPE="$(echo "$RULE" | cut -d':' -f1)"
  TARGET_NAME="$(echo "$RULE" | cut -d':' -f2)"
  TARGET_TYPE="$(echo "$RULE" | cut -d':' -f3)"
  TARGET_VALUE="$(echo "$RULE" | cut -d':' -f4)"

  local VALID_METRIC_TYPES=("external" "ingress" "pods" "resource")
  if ! fn-in-array "$METRIC_TYPE" "${VALID_METRIC_TYPES[@]}"; then
    dokku_log_fail "Invalid metric type '${METRIC_TYPE}'"
  fi

  if [[ -z "$TARGET_NAME" ]]; then
    dokku_log_fail "Missing target name in rule"
  fi
  if [[ -z "$TARGET_TYPE" ]]; then
    dokku_log_fail "Missing target type in rule"
  fi
  if [[ -z "$TARGET_VALUE" ]]; then
    dokku_log_fail "Missing target value in rule"
  fi

  local VALID_TARGET_TYPES=()
  if [[ "$METRIC_TYPE" == "external" ]]; then
    VALID_TARGET_TYPES=("AverageValue" "Value")
  elif [[ "$METRIC_TYPE" == "ingress" ]]; then
    VALID_TARGET_TYPES=("AverageValue" "Value")
  elif [[ "$METRIC_TYPE" == "pods" ]]; then
    VALID_TARGET_TYPES=("AverageValue")
  elif [[ "$METRIC_TYPE" == "resource" ]]; then
    VALID_TARGET_TYPES=("AverageValue" "Utilization")
    local VALID_TARGET_NAMES=("cpu" "memory")
    if ! fn-in-array "$TARGET_NAME" "${VALID_TARGET_NAMES[@]}"; then
      dokku_log_fail "Invalid target name '${TARGET_NAME}', valid types: ${VALID_TARGET_NAMES[*]}"
    fi
  fi

  if ! fn-in-array "$TARGET_TYPE" "${VALID_TARGET_TYPES[@]}"; then
    dokku_log_fail "Invalid target type '${TARGET_TYPE}', valid types: ${VALID_TARGET_TYPES[*]}"
  fi
}

fn-scheduler-kubernetes-ingress-build-config() {
  declare desc="scheduler-kubernetes ingress-build-config"
  declare APP="$1"

  if [[ "$(plugn trigger proxy-type "$APP")" != "nginx-ingress" ]]; then
    return
  fi

  if [[ "$(is_app_vhost_enabled "$APP")" == "false" ]]; then
    dokku_log_info1 "VHOST support disabled"
    return
  fi

  if [[ ! -f "$DOKKU_ROOT/$APP/VHOST" ]]; then
    domains_setup "$APP"
  fi

  export KUBECONFIG="${DOKKU_ROOT}/.kube/config"
  local CERT_MANAGER_EMAIL="$(config_get --global CERT_MANAGER_EMAIL || true)"
  local CERT_MANAGER_DOMAINS=()
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  if [[ -n "$CERT_MANAGER_EMAIL" ]]; then
    local CERTIFICATE_ISSUER_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/certificate-issuer.json.sigil"
    local SIGIL_PARAMS=(CERT_MANAGER_EMAIL="$CERT_MANAGER_EMAIL")
    sigil -f "$CERTIFICATE_ISSUER_TEMPLATE" "${SIGIL_PARAMS[@]}" | cat -s >"$TMP_FILE"
    "${DOKKU_LIB_ROOT}/data/scheduler-kubernetes/kubectl" apply -f "$TMP_FILE" | sed "s/^/       /"
  fi

  local HAS_RULE=false
  local APP_NAMESPACE="$(fn-plugin-property-get "scheduler-kubernetes" "$APP" "namespace" "default")"
  local INGRESS_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/ingress.json.sigil"

  local SIGIL_PARAMS=()
  sigil -f "$INGRESS_TEMPLATE" "${SIGIL_PARAMS[@]}" | cat -s >"$TMP_FILE"

  for app in $(dokku_apps); do
    local DOKKU_VHOST_FILE="$DOKKU_ROOT/$app/VHOST"
    local namespace="$(fn-plugin-property-get "scheduler-kubernetes" "$app" "namespace" "default")"
    local cert_manager_enabled="$(fn-plugin-property-get "scheduler-kubernetes" "$app" "cert-manager-enabled" "")"

    if [[ "$APP_NAMESPACE" != "$namespace" ]]; then
      continue
    fi

    if [[ ! -f "$DOKKU_VHOST_FILE" ]]; then
      continue
    fi

    if [[ "$(plugn trigger proxy-type "$app")" != "nginx-ingress" ]]; then
      continue
    fi

    if [[ "$(is_app_vhost_enabled "$app")" == "false" ]]; then
      continue
    fi

    while read -r line || [[ -n "$line" ]]; do
      [[ "$line" =~ ^#.* ]] && continue
      line="$(strip_inline_comments "$line")"
      PROC_TYPE=${line%%=*}
      PROC_COUNT=${line#*=}

      if [[ "$PROC_TYPE" != "web" ]]; then
        continue
      fi

      while read -r DOMAIN || [[ -n "$DOMAIN" ]]; do
        if [[ "$cert_manager_enabled" == "true" ]]; then
          CERT_MANAGER_DOMAINS+=("$DOMAIN")
        fi

        HAS_RULE=true
        fn-scheduler-kubernetes-add-ingress-rule "$app" "$PROC_TYPE" "5000" "$DOMAIN" "$TMP_FILE"
      done <"$DOKKU_VHOST_FILE"
    done < <(plugn trigger ps-current-scale "$app")
  done

  if [[ "$HAS_RULE" == "false" ]]; then
    return
  fi

  local KUBE_ARGS=()
  KUBE_ARGS+=("--namespace=$APP_NAMESPACE")
  fn-scheduler-kubernetes-ensure-namespace "$APP_NAMESPACE" >/dev/null

  local SCHEME=http
  if [[ -n "$CERT_MANAGER_EMAIL" ]] && [[ -n "$CERT_MANAGER_DOMAINS" ]]; then
    local SCHEME=https
    fn-scheduler-kubernetes-add-cert-manager "$TMP_FILE" "${CERT_MANAGER_DOMAINS[@]}"
  fi

  fn-set-ingress-annotations "$APP_NAMESPACE" "$TMP_FILE"
  plugn trigger pre-kubernetes-ingress-apply "$APP" "$TMP_FILE"
  "${DOKKU_LIB_ROOT}/data/scheduler-kubernetes/kubectl" "${KUBE_ARGS[@]}" apply -f "$TMP_FILE" | sed "s/^/       /"

  local URLS_PATH="$DOKKU_ROOT/$APP/URLS"
  local NONSSL_VHOSTS=$(get_app_domains "$APP")
  if [[ -n "$NONSSL_VHOSTS" ]]; then
    echo "# THIS FILE IS GENERATED BY DOKKU - DO NOT EDIT, YOUR CHANGES WILL BE OVERWRITTEN" >"$URLS_PATH"
    xargs -i echo "$SCHEME://{}" <<<"$(echo "${NONSSL_VHOSTS}" | tr ' ' '\n' | sort -u)" >>"$URLS_PATH"
  fi
}

fn-scheduler-kubernetes-ensure-namespace() {
  declare NAMESPACE="$1"
  if [[ "$NAMESPACE" = "default" ]]; then
    return
  fi

  local NAMESPACE_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/namespace.json.sigil"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  SIGIL_PARAMS=(NAME="$NAMESPACE")
  sigil -f "$NAMESPACE_TEMPLATE" "${SIGIL_PARAMS[@]}" | cat -s >"$TMP_FILE"

  "${DOKKU_LIB_ROOT}/data/scheduler-kubernetes/kubectl" apply -f "$TMP_FILE" | sed "s/^/       /"
}

fn-set-deployment-annotations() {
  declare APP="$1" DEPLOYMENT_FILE="$2"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  ANNOTATION_COUNT="$(fn-plugin-property-list-length "scheduler-kubernetes" "$APP" "deployment-annotations")"
  if [[ "$ANNOTATION_COUNT" == 0 ]]; then
    return
  fi

  jq -M --argjson data "{}" '.metadata.annotations += $data' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$DEPLOYMENT_FILE"

  while IFS="" read -r p || [ -n "$p" ]; do
    local KEY="$(echo "$p" | cut -d' ' -f1)"
    local VALUE="$(echo "$p" | cut -d' ' -f2)"
    KEY="$KEY" VALUE="$VALUE" jq -M '.metadata.annotations[env.KEY] = env.VALUE' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  done < <(fn-plugin-property-list-get "scheduler-kubernetes" "$APP" "deployment-annotations")
}

fn-set-env-vars() {
  declare APP="$1" DEPLOYMENT_FILE="$2"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  jq -M --argjson data "$(config_export app "$APP" --format json-list --merged)" '.spec.template.spec.containers[0].env += $data' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$DEPLOYMENT_FILE"
}

fn-set-healthchecks() {
  declare APP="$1" PROC_TYPE="$2" DEPLOYMENT_FILE="$3"
  local TMP_DIR=$(mktemp -d "/tmp/${FUNCNAME[0]}.XXXX")
  local APP_JSON_TMPL="$TMP_DIR/app.json.sigil"
  local APP_JSON_FILE="$TMP_DIR/app.json"
  local PROBE_FILE="$TMP_DIR/probe.json"
  local DEPLOYMENT_TMP_FILE="$TMP_DIR/deployment.json"
  trap 'rm -rf "$TMP_DIR" > /dev/null' RETURN INT TERM EXIT

  copy_from_image "$IMAGE" "app.json" "$APP_JSON_TMPL" 2>/dev/null || true

  if [[ ! -f "$APP_JSON_TMPL" ]]; then
    return 0
  fi

  # We use sigil templating to allow the health check configurations to refer
  # to the app name with the variable $APP.
  local SIGIL_PARAMS=(APP="$APP")
  sigil -f "$APP_JSON_TMPL" "${SIGIL_PARAMS[@]}" | cat -s >"$APP_JSON_FILE"

  for PROBE_TYPE in liveness readiness; do
    if jq -e -M ".healthchecks.\"$PROC_TYPE\".\"$PROBE_TYPE\"" <"$APP_JSON_FILE" >"$PROBE_FILE" \
      || jq -e -M ".healthchecks.\"*\".\"$PROBE_TYPE\"" <"$APP_JSON_FILE" >"$PROBE_FILE"; then
      jq -M --argjson data "$(cat "$PROBE_FILE")" ".spec.template.spec.containers[0].${PROBE_TYPE}Probe += \$data" <"$DEPLOYMENT_FILE" >"$DEPLOYMENT_TMP_FILE"
      mv "$DEPLOYMENT_TMP_FILE" "$DEPLOYMENT_FILE"
    fi
  done
}

fn-set-image-pull-secrets() {
  declare IMAGE_PULL_SECRETS="$1" DEPLOYMENT_FILE="$2"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  if [[ -n "$IMAGE_PULL_SECRETS" ]]; then
    IMAGE_PULL_SECRETS="$IMAGE_PULL_SECRETS" jq -M ".spec.template.spec.imagePullSecrets[0].name = env.IMAGE_PULL_SECRETS" <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  fi
}

fn-set-pod-annotations() {
  declare APP="$1" DEPLOYMENT_FILE="$2"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  ANNOTATION_COUNT="$(fn-plugin-property-list-length "scheduler-kubernetes" "$APP" "pod-annotations")"
  if [[ "$ANNOTATION_COUNT" == 0 ]]; then
    return
  fi

  jq -M --argjson data "{}" '.spec.template.metadata.annotations += $data' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$DEPLOYMENT_FILE"

  while IFS="" read -r p || [ -n "$p" ]; do
    local KEY="$(echo "$p" | cut -d' ' -f1)"
    local VALUE="$(echo "$p" | cut -d' ' -f2)"
    KEY="$KEY" VALUE="$VALUE" jq -M '.spec.template.metadata.annotations[env.KEY] = env.VALUE' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  done < <(fn-plugin-property-list-get "scheduler-kubernetes" "$APP" "pod-annotations")
}

fn-set-ports() {
  declare APP="$1" DEPLOYMENT_FILE="$2"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  if is_image_herokuish_based "$IMAGE"; then
    jq -M --argjson data "[{\"name\": \"PORT\", \"value\": \"5000\"}]" '.spec.template.spec.containers[0].env += $data' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  fi
}

fn-set-pod-disruption-constraints() {
  declare APP="$1"
  local POD_TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  MIN_AVAILABLE="$(fn-plugin-property-get "scheduler-kubernetes" "$APP" "pod-min-available" "")"
  MAX_UNAVAILABLE="$(fn-plugin-property-get "scheduler-kubernetes" "$APP" "pod-max-unavailable" "")"

  if [[ -z "$MIN_AVAILABLE" ]] && [[ -z "$MAX_UNAVAILABLE" ]]; then
    return
  fi

  export KUBECONFIG="${DOKKU_ROOT}/.kube/config"
  KUBE_ARGS=()
  NAMESPACE="$(fn-plugin-property-get "scheduler-kubernetes" "$APP" "namespace" "default")"
  KUBE_ARGS+=("--namespace=$NAMESPACE")
  fn-scheduler-kubernetes-ensure-namespace "$NAMESPACE" >/dev/null

  local SIGIL_PARAMS=(APP="$APP")
  sigil -f "$DEPLOYMENT_TEMPLATE" "${SIGIL_PARAMS[@]}" | cat -s >"$POD_TMP_FILE"

  if [[ -n "$MIN_AVAILABLE" ]]; then
    MIN_AVAILABLE="$MIN_AVAILABLE" jq -M '.spec.minAvailable = (env.MIN_AVAILABLE|tonumber)' <"$POD_TMP_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$POD_TMP_FILE"
  fi

  if [[ -n "$MAX_UNAVAILABLE" ]]; then
    MAX_UNAVAILABLE="$MAX_UNAVAILABLE" jq -M '.spec.maxUnavailable = (env.MAX_UNAVAILABLE|tonumber)' <"$POD_TMP_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$POD_TMP_FILE"
  fi

  dokku_log_info1 "Creating PodDisruptionBudget for ${APP}"
  "${DOKKU_LIB_ROOT}/data/scheduler-kubernetes/kubectl" "${KUBE_ARGS[@]}" apply -f "$POD_TMP_FILE" | sed "s/^/       /"
}

fn-set-resource-constraints() {
  declare APP="$1" PROC_TYPE="$2" DEPLOYMENT_FILE="$3"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  RESOURCE_LIMITS_CPU=$(plugn trigger resource-get-property "$APP" "$PROC_TYPE" "limit" "cpu" 2>/dev/null || true)
  RESOURCE_LIMITS_NVIDIA_GPU=$(plugn trigger resource-get-property "$APP" "$PROC_TYPE" "limit" "nvidia-gpu" 2>/dev/null || true)
  RESOURCE_LIMITS_MEMORY=$(plugn trigger resource-get-property "$APP" "$PROC_TYPE" "limit" "memory" 2>/dev/null || true)
  RESOURCE_REQUESTS_CPU=$(plugn trigger resource-get-property "$APP" "$PROC_TYPE" "reserve" "cpu" 2>/dev/null || true)
  RESOURCE_REQUESTS_MEMORY=$(plugn trigger resource-get-property "$APP" "$PROC_TYPE" "reserve" "memory" 2>/dev/null || true)

  if [[ -n "$RESOURCE_LIMITS_CPU" ]]; then
    RESOURCE_LIMITS_CPU="$RESOURCE_LIMITS_CPU" jq -M ".spec.template.spec.containers[0].resources.limits.cpu = env.RESOURCE_LIMITS_CPU" <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  fi

  if [[ -n "$RESOURCE_LIMITS_NVIDIA_GPU" ]] && [[ "$RESOURCE_LIMITS_NVIDIA_GPU" != "0" ]]; then
    re='^[0-9]+$'
    if [[ "$RESOURCE_LIMITS_NVIDIA_GPU" =~ $re ]]; then
      RESOURCE_LIMITS_NVIDIA_GPU="$RESOURCE_LIMITS_NVIDIA_GPU" jq -M '.spec.template.spec.containers[0].resources.limits["nvidia.com/gpu"] = (env.RESOURCE_LIMITS_NVIDIA_GPU|tonumber)' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    else
      RESOURCE_LIMITS_NVIDIA_GPU="$RESOURCE_LIMITS_NVIDIA_GPU" jq -M '.spec.template.spec.containers[0].resources.limits["nvidia.com/gpu"] = env.RESOURCE_LIMITS_NVIDIA_GPU' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    fi
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  fi

  if [[ -n "$RESOURCE_LIMITS_MEMORY" ]]; then
    if [[ "$RESOURCE_LIMITS_MEMORY" =~ ^[0-9]+$ ]]; then
      RESOURCE_LIMITS_MEMORY="${RESOURCE_LIMITS_MEMORY}Mi"
    fi
    RESOURCE_LIMITS_MEMORY="$RESOURCE_LIMITS_MEMORY" jq -M ".spec.template.spec.containers[0].resources.limits.memory = env.RESOURCE_LIMITS_MEMORY" <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  fi

  if [[ -n "$RESOURCE_REQUESTS_CPU" ]]; then
    RESOURCE_REQUESTS_CPU="$RESOURCE_REQUESTS_CPU" jq -M ".spec.template.spec.containers[0].resources.requests.cpu = env.RESOURCE_REQUESTS_CPU" <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  fi

  if [[ -n "$RESOURCE_REQUESTS_MEMORY" ]]; then
    if [[ "$RESOURCE_REQUESTS_MEMORY" =~ ^[0-9]+$ ]]; then
      RESOURCE_REQUESTS_MEMORY="${RESOURCE_REQUESTS_MEMORY}Mi"
    fi
    RESOURCE_REQUESTS_MEMORY="$RESOURCE_REQUESTS_MEMORY" jq -M ".spec.template.spec.containers[0].resources.requests.memory = env.RESOURCE_REQUESTS_MEMORY" <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  fi
}

fn-set-service-annotations() {
  declare APP="$1" DEPLOYMENT_FILE="$2"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  ANNOTATION_COUNT="$(fn-plugin-property-list-length "scheduler-kubernetes" "$APP" "service-annotations")"
  if [[ "$ANNOTATION_COUNT" == 0 ]]; then
    return
  fi

  jq -M --argjson data "{}" '.metadata.annotations += $data' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$DEPLOYMENT_FILE"

  while IFS="" read -r p || [ -n "$p" ]; do
    local KEY="$(echo "$p" | cut -d' ' -f1)"
    local VALUE="$(echo "$p" | cut -d' ' -f2)"
    KEY="$KEY" VALUE="$VALUE" jq -M '.metadata.annotations[env.KEY] = env.VALUE' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  done < <(fn-plugin-property-list-get "scheduler-kubernetes" "$APP" "service-annotations")
}

fn-strip-ports() {
  declare DEPLOYMENT_FILE="$1"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")

  jq -M 'del(.spec.template.spec.containers[0].ports)' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$DEPLOYMENT_FILE"
}

fn-set-ingress-annotations() {
  declare APP_NAMESPACE="$1" INGRESS_FILE="$2"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  ANNOTATION_COUNT="$(fn-plugin-property-list-length "scheduler-kubernetes" "$APP_NAMESPACE" "ingress-annotations")"
  if [[ "$ANNOTATION_COUNT" == 0 ]]; then
    return
  fi

  jq -M --argjson data "{}" '.metadata.annotations += $data' <"$INGRESS_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$INGRESS_FILE"

  while IFS="" read -r p || [ -n "$p" ]; do
    local KEY="$(echo "$p" | cut -d' ' -f1)"
    local VALUE="$(echo "$p" | cut -d' ' -f2)"
    KEY="$KEY" VALUE="$VALUE" jq -M '.metadata.annotations[env.KEY] = env.VALUE' <"$INGRESS_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$INGRESS_FILE"
  done < <(fn-plugin-property-list-get "scheduler-kubernetes" "$APP_NAMESPACE" "ingress-annotations")
}

fn-scheduler-kubernetes-add-pvc() {
  declare desc="add persistent volume claim"
  declare NAME="$1" ACCESS_MODE="$2" STORAGE="$3" STORAGE_CLASS_NAME="$4" NAMESPACE="$5"

  export KUBECONFIG="${DOKKU_ROOT}/.kube/config"
  export KUBEDOG_KUBE_CONFIG="${DOKKU_ROOT}/.kube/config"
  KUBE_ARGS=()
  if [[ -n "$NAMESPACE" ]]; then
    KUBE_ARGS+=("--namespace=$NAMESPACE")
    fn-scheduler-kubernetes-ensure-namespace "$NAMESPACE" >/dev/null
  fi

  local PVC_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/pvc.json.sigil"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  if [[ "$STORAGE_CLASS_NAME" != "" ]]; then
    STORAGE_CLASS_NAME="$STORAGE_CLASS_NAME" jq -M '.spec.storageClassName = env.STORAGE_CLASS_NAME' <"$PVC_TEMPLATE" >"$TMP_FILE"
  else
    cp "$PVC_TEMPLATE" "$TMP_FILE"
  fi
  SIGIL_PARAMS=(NAME="$NAME" ACCESS_MODE="$ACCESS_MODE" STORAGE="$STORAGE")
  sigil -f "$TMP_FILE" "${SIGIL_PARAMS[@]}" | "${DOKKU_LIB_ROOT}/data/scheduler-kubernetes/kubectl" "${KUBE_ARGS[@]}" apply -f - | sed "s/^/       /"
}

cmd-scheduler-kubernetes-list-pvc() {
  declare desc="list persistent volume claims per namesapce"
  declare NAMESPACE="$1"

  export KUBECONFIG="${DOKKU_ROOT}/.kube/config"
  export KUBEDOG_KUBE_CONFIG="${DOKKU_ROOT}/.kube/config"
  KUBE_ARGS=()
  if [[ -n "$NAMESPACE" ]]; then
    KUBE_ARGS+=("--namespace=$NAMESPACE")
  fi

  "${DOKKU_LIB_ROOT}/data/scheduler-kubernetes/kubectl" "${KUBE_ARGS[@]}" get pvc
}

fn-scheduler-kubernetes-remove-pvc() {
  declare desc="remove persistent volume claim from namesapce"
  declare NAME="$1" NAMESPACE="$2"

  export KUBECONFIG="${DOKKU_ROOT}/.kube/config"
  export KUBEDOG_KUBE_CONFIG="${DOKKU_ROOT}/.kube/config"
  KUBE_ARGS=()
  if [[ -n "$NAMESPACE" ]]; then
    KUBE_ARGS+=("--namespace=$NAMESPACE")
  fi

  "${DOKKU_LIB_ROOT}/data/scheduler-kubernetes/kubectl" "${KUBE_ARGS[@]}" delete pvc "$NAME"
}

fn-set-command-and-args() {
  declare desc="set the command and args"
  declare APP="$1" PROC_TYPE="$2" IMAGE_SOURCE_TYPE="$3" DEPLOYMENT_FILE="$4"

  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  DOKKU_HEROKUISH=false
  [[ "$IMAGE_SOURCE_TYPE" == "herokuish" ]] && DOKKU_HEROKUISH=true

  local command_with_args="$(fn-scheduler-kubernetes-extract-start-cmd "$APP" "$PROC_TYPE" "$DOKKU_HEROKUISH" 5000)"
  if [[ -z "$command_with_args" ]]; then
    dokku_log_fail "No $PROC_TYPE command detected for app"
    return
  fi

  COMMAND=""
  ARGS=()
  i=0
  for word in ${command_with_args[@]}; do
    [[ "$i" -eq 0 ]] && COMMAND="$word"
    [[ "$i" -ne 0 ]] && ARGS+=("$word")
    i=$((i + 1))
  done

  COMMAND="$COMMAND" jq -M ".spec.template.spec.containers[0].command = [env.COMMAND]" <"$DEPLOYMENT_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  jq -M ".spec.template.spec.containers[0].args = []" <"$DEPLOYMENT_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$DEPLOYMENT_FILE"

  for ARG in "${ARGS[@]}"; do
    ARG="$ARG" jq -M ".spec.template.spec.containers[0].args += [env.ARG]" <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  done
}

fn-scheduler-kubernetes-extract-start-cmd() {
  declare APP="$1" PROC_TYPE="$2" DOKKU_HEROKUISH="$3" PORT="$4"
  local DOKKU_DOCKERFILE_START_CMD DOKKU_PROCFILE_START_CMD START_CMD

  local START_CMD
  [[ "$DOKKU_HEROKUISH" == "true" ]] && START_CMD="/start $PROC_TYPE"
  DOKKU_START_CMD=$(config_get "$APP" DOKKU_START_CMD || true)
  [[ -n "$DOKKU_START_CMD" ]] && START_CMD="$DOKKU_START_CMD"

  if [[ "$DOKKU_HEROKUISH" != "false" ]]; then
    echo "$START_CMD"
    return
  fi

  DOKKU_DOCKERFILE_START_CMD=$(config_get "$APP" DOKKU_DOCKERFILE_START_CMD || true)
  DOKKU_PROCFILE_START_CMD=$(plugn trigger procfile-get-command "$APP" "$PROC_TYPE" "$PORT")
  START_CMD=${DOKKU_DOCKERFILE_START_CMD:-$DOKKU_PROCFILE_START_CMD}
  echo "$START_CMD"
}

fn-set-mount() {
  declare desc="mount volumes on path"
  declare APP="$1" DEPLOYMENT_FILE="$2"

  VOLUME_COUNT="$(fn-plugin-property-list-length "scheduler-kubernetes" "$APP" "volumes")"
  if [[ "$VOLUME_COUNT" == 0 ]]; then
    return
  fi
  local VOLUMES_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/volumes.json.sigil"
  local VOLUME_MOUNTS_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/volume-mounts.json.sigil"

  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  VOLUMES="$(fn-plugin-property-list-get "scheduler-kubernetes" "$APP" "volumes")"
  for VOLUME_ENTRY in ${VOLUMES[@]}; do
    local CLAIM_NAME=$(echo "$VOLUME_ENTRY" | cut -d':' -f1)
    local MOUNT_PATH=$(echo "$VOLUME_ENTRY" | cut -d':' -f2)

    local SIGIL_PARAMS=(VOLUME_NAME="$CLAIM_NAME" CLAIM_NAME="$CLAIM_NAME")
    jq --argjson volume "$(sigil -f "$VOLUMES_TEMPLATE" "${SIGIL_PARAMS[@]}")" '.spec.template.spec.volumes += [$volume]' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"

    local SIGIL_PARAMS=(VOLUME_NAME="$CLAIM_NAME" MOUNT_PATH="$MOUNT_PATH")
    jq --argjson mount "$(sigil -f "$VOLUME_MOUNTS_TEMPLATE" "${SIGIL_PARAMS[@]}")" '.spec.template.spec.containers[0].volumeMounts += [$mount]' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  done
}
