#!/usr/bin/env bash
source "$PLUGIN_CORE_AVAILABLE_PATH/common/functions"
source "$PLUGIN_CORE_AVAILABLE_PATH/common/property-functions"
source "$PLUGIN_AVAILABLE_PATH/config/functions"
source "$PLUGIN_AVAILABLE_PATH/domains/functions"
set -eo pipefail
[[ $DOKKU_TRACE ]] && set -x

cmd-scheduler-kubernetes-rolling-update() {
  declare desc="force a rolling update"
  declare cmd="scheduler-kubernetes:rolling-update" argv=("$@")
  [[ ${argv[0]} == "$cmd" ]] && shift 1
  declare APP="$1"

  local DOKKU_SCHEDULER=$(get_app_scheduler "$APP")
  if [[ "$DOKKU_SCHEDULER" != "kubernetes" ]]; then
    dokku_log_fail "Scheduler for $APP is set to $DOKKU_SCHEDULER"
    return 1
  fi

  local DOKKU_SCALE_FILE="$DOKKU_ROOT/$APP/DOKKU_SCALE"
  if [[ ! -f "$DOKKU_SCALE_FILE" ]]; then
    dokku_log_fail "No processes found for $APP"
    return 1
  fi

  export KUBECONFIG="${DOKKU_ROOT}/.kube/config"
  export KUBEDOG_KUBE_CONFIG="${DOKKU_ROOT}/.kube/config"
  KUBE_ARGS=()
  NAMESPACE="$(fn-plugin-property-get "scheduler-kubernetes" "$APP" "namespace" "")"
  if [[ -n "$NAMESPACE" ]]; then
    KUBE_ARGS+=("--namespace=$NAMESPACE")
    fn-scheduler-kubernetes-ensure-namespace "$NAMESPACE" >/dev/null
  fi

  dokku_log_info1 "Triggering rolling-update for $APP"
  while read -r line || [[ -n "$line" ]]; do
    [[ "$line" =~ ^#.* ]] && continue
    line="$(strip_inline_comments "$line")"
    PROC_TYPE=${line%%=*}

    "${DOKKU_LIB_ROOT}/data/scheduler-kubernetes/kubectl" "${KUBE_ARGS[@]}" patch deployment "${APP}-${PROC_TYPE}" --patch "{\"spec\":{\"template\":{\"metadata\":{\"labels\":{\"dokku.com/rolling-update-time\":\"$(date -u "+%Y-%m-%d-%H-%M-%S")\"}}}}}" | sed "s/^/       /"
  done <"$DOKKU_SCALE_FILE"
}

cmd-scheduler-kubernetes-report() {
  declare desc="displays a scheduler-kubernetes report for one or more apps"
  declare cmd="scheduler-kubernetes:report"
  local INSTALLED_APPS=$(dokku_apps)
  local APP="$2" INFO_FLAG="$3"

  if [[ -n "$APP" ]] && [[ "$APP" == --* ]]; then
    INFO_FLAG="$APP"
    APP=""
  fi

  if [[ -z "$APP" ]] && [[ -z "$INFO_FLAG" ]]; then
    INFO_FLAG="true"
  fi

  if [[ -z "$APP" ]]; then
    for app in $INSTALLED_APPS; do
      cmd-scheduler-kubernetes-report-single "$app" "$INFO_FLAG" | tee || true
    done
  else
    cmd-scheduler-kubernetes-report-single "$APP" "$INFO_FLAG"
  fi
}

cmd-scheduler-kubernetes-report-single() {
  declare APP="$1" INFO_FLAG="$2"
  if [[ "$INFO_FLAG" == "true" ]]; then
    INFO_FLAG=""
  fi
  verify_app_name "$APP"
  local flag_map=(
    "--scheduler-kubernetes-cert-manager-enabled: $(fn-plugin-property-get "scheduler-kubernetes" "$APP" "cert-manager-enabled" "")"
    "--scheduler-kubernetes-imagePullSecrets: $(fn-plugin-property-get "scheduler-kubernetes" "$APP" "imagePullSecrets" "")"
    "--scheduler-kubernetes-ingress-enabled: $(fn-plugin-property-get "scheduler-kubernetes" "$APP" "ingress-enabled" "false")"
    "--scheduler-kubernetes-namespace: $(fn-plugin-property-get "scheduler-kubernetes" "$APP" "namespace" "")"
    "--scheduler-kubernetes-pod-max-unavailable: $(fn-plugin-property-get "scheduler-kubernetes" "$APP" "pod-max-unavailable" "")"
    "--scheduler-kubernetes-pod-min-available: $(fn-plugin-property-get "scheduler-kubernetes" "$APP" "pod-min-available" "")"
  )

  if [[ -z "$INFO_FLAG" ]]; then
    dokku_log_info2_quiet "${APP} scheduler-kubernetes information"
    for flag in "${flag_map[@]}"; do
      key="$(echo "${flag#--}" | cut -f1 -d' ' | tr - ' ')"
      dokku_log_verbose "$(printf "%-30s %-25s" "${key^}" "${flag#*: }")"
    done
  else
    local match=false
    local value_exists=false
    for flag in "${flag_map[@]}"; do
      valid_flags="${valid_flags} $(echo "$flag" | cut -d':' -f1)"
      if [[ "$flag" == "${INFO_FLAG}:"* ]]; then
        value=${flag#*: }
        size="${#value}"
        if [[ "$size" -ne 0 ]]; then
          echo "$value" && match=true && value_exists=true
        else
          match=true
        fi
      fi
    done
    [[ "$match" == "true" ]] || dokku_log_fail "Invalid flag passed, valid flags:${valid_flags}"
    [[ "$value_exists" == "true" ]] || dokku_log_fail "not deployed"
  fi
}

scheduler_docker_local_help_content_func() {
  declare desc="return scheduler-kubernetes plugin help content"
  cat <<help_content
    scheduler-kubernetes:autoscale-set <app> <proc_type> <key> <value>, Set or clear a scheduler-kubernetes autoscale settings for an app
    scheduler-kubernetes:deployment-annotations-set <app> <key> <value>, Set or clear a scheduler-kubernetes deployment annotation for an app
    scheduler-kubernetes:pod-annotations-set <app> <key> <value>, Set or clear a scheduler-kubernetes pod annotation for an app
    scheduler-kubernetes:report [<app>] [<flag>], Displays a scheduler-kubernetes report for one or more apps
    scheduler-kubernetes:rolling-update <app>, Force a rolling update
    scheduler-kubernetes:service-annotations-set <app> <key> <value>, Set or clear a scheduler-kubernetes service annotation for an app
    scheduler-kubernetes:set <app> <property> (<value>), Set or clear a scheduler-kubernetes property for an app
    scheduler-kubernetes:show-manifest <app> <proc_type> (<manifest_type>), Display the deployment or service manifest for a given app/process type combination
help_content
}

cmd-scheduler-kubernetes-help() {
  if [[ $1 == "scheduler-kubernetes:help" ]]; then
    echo -e 'Usage: dokku scheduler-kubernetes[:COMMAND]'
    echo ''
    echo 'Manages the scheduler-kubernetes integration for an app.'
    echo ''
    echo 'Additional commands:'
    scheduler_docker_local_help_content_func | sort | column -c2 -t -s,
    echo ''
  elif [[ $(ps -o command= $PPID) == *"--all"* ]]; then
    scheduler_docker_local_help_content_func
  else
    cat <<help_desc
    scheduler-kubernetes, Manages the scheduler-kubernetes integration for an app
help_desc
  fi
}

fn-scheduler-kubernetes-add-cert-manager() {
  declare INGRESS_FILE="$1" CERT_MANAGER_DOMAINS="${@:2}"
  local CERT_MANAGER_TLS_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/cert-manager-tls.json.sigil"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  jq --argjson tls "$(sigil -f "$CERT_MANAGER_TLS_TEMPLATE")" '.spec.tls += $tls' <"$INGRESS_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$INGRESS_FILE"

  for domain in ${CERT_MANAGER_DOMAINS[*]}; do
    DOMAIN="$domain" jq '.spec.tls[0].hosts += [env.DOMAIN]' <"$INGRESS_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$INGRESS_FILE"
  done

  jq -M '.metadata.annotations["cert-manager.io/cluster-issuer"] = "letsencrypt-prod"' <"$INGRESS_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$INGRESS_FILE"
}

fn-scheduler-kubernetes-add-ingress-rule() {
  declare APP="$1" PROC_TYPE="$2" PORT="$3" DOMAIN="$4" INGRESS_FILE="$5"
  local RULE_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/ingress-rule.json.sigil"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  local SIGIL_PARAMS=(APP="$APP" PROCESS_TYPE="$PROC_TYPE" PORT="$PORT" DOMAIN="$DOMAIN")
  jq --argjson rule "$(sigil -f "$RULE_TEMPLATE" "${SIGIL_PARAMS[@]}")" '.spec.rules += [$rule]' <"$INGRESS_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$INGRESS_FILE"
}

fn-scheduler-kubernetes-autoscale-rule-validate() {
  declare desc="validate an autoscale rule"
  declare RULE="$1"
  local METRIC_TYPE TARGET_NAME TARGET_TYPE TARGET_VALUE

  METRIC_TYPE="$(echo "$RULE" | cut -d':' -f1)"
  TARGET_NAME="$(echo "$RULE" | cut -d':' -f2)"
  TARGET_TYPE="$(echo "$RULE" | cut -d':' -f3)"
  TARGET_VALUE="$(echo "$RULE" | cut -d':' -f4)"

  local VALID_METRIC_TYPES=("external" "ingress" "pods" "resource")
  if ! fn-in-array "$METRIC_TYPE" "${VALID_METRIC_TYPES[@]}"; then
    dokku_log_fail "Invalid metric type '${METRIC_TYPE}'"
  fi

  if [[ -z "$TARGET_NAME" ]]; then
    dokku_log_fail "Missing target name in rule"
  fi
  if [[ -z "$TARGET_TYPE" ]]; then
    dokku_log_fail "Missing target type in rule"
  fi
  if [[ -z "$TARGET_VALUE" ]]; then
    dokku_log_fail "Missing target value in rule"
  fi

  local VALID_TARGET_TYPES=()
  if [[ "$METRIC_TYPE" == "external" ]]; then
    VALID_TARGET_TYPES=("AverageValue" "Value")
  elif [[ "$METRIC_TYPE" == "ingress" ]]; then
    VALID_TARGET_TYPES=("AverageValue" "Value")
  elif [[ "$METRIC_TYPE" == "pods" ]]; then
    VALID_TARGET_TYPES=("AverageValue")
  elif [[ "$METRIC_TYPE" == "resource" ]]; then
    VALID_TARGET_TYPES=("AverageValue" "Utilization")
    local VALID_TARGET_NAMES=("cpu" "memory")
    if ! fn-in-array "$TARGET_NAME" "${VALID_TARGET_NAMES[@]}"; then
      dokku_log_fail "Invalid target name '${TARGET_NAME}', valid types: ${VALID_TARGET_NAMES[@]}"
    fi
  fi

  if ! fn-in-array "$TARGET_TYPE" "${VALID_TARGET_TYPES[@]}"; then
    dokku_log_fail "Invalid target type '${TARGET_TYPE}', valid types: ${VALID_TARGET_TYPES[@]}"
  fi
}

fn-scheduler-kubernetes-ingress-build-config() {
  declare desc="scheduler-kubernetes ingress-build-config"
  declare APP="$1"

  if [[ "$(plugn trigger proxy-type "$APP")" != "nginx-ingress" ]]; then
    return
  fi

  if [[ "$(is_app_vhost_enabled "$APP")" == "false" ]]; then
    dokku_log_info1 "VHOST support disabled"
    return
  fi

  if [[ ! -f "$DOKKU_ROOT/$APP/VHOST" ]]; then
    domains_setup "$APP"
  fi

  export KUBECONFIG="${DOKKU_ROOT}/.kube/config"
  local CERT_MANAGER_EMAIL="$(config_get --global CERT_MANAGER_EMAIL || true)"
  local CERT_MANAGER_DOMAINS=()
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  if [[ -n "$CERT_MANAGER_EMAIL" ]]; then
    local CERTIFICATE_ISSUER_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/certificate-issuer.json.sigil"
    local SIGIL_PARAMS=(CERT_MANAGER_EMAIL="$CERT_MANAGER_EMAIL")
    sigil -f "$CERTIFICATE_ISSUER_TEMPLATE" "${SIGIL_PARAMS[@]}" | cat -s >$TMP_FILE
    "${DOKKU_LIB_ROOT}/data/scheduler-kubernetes/kubectl" apply -f "$TMP_FILE" | sed "s/^/       /"
  fi

  local HAS_RULE=false
  local APP_NAMESPACE="$(fn-plugin-property-get "scheduler-kubernetes" "$APP" "namespace" "")"
  local INGRESS_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/ingress.json.sigil"
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  local SIGIL_PARAMS=()
  sigil -f "$INGRESS_TEMPLATE" "${SIGIL_PARAMS[@]}" | cat -s >$TMP_FILE

  for app in $(dokku_apps); do
    local DOKKU_SCALE_FILE="$DOKKU_ROOT/$app/DOKKU_SCALE"
    local DOKKU_VHOST_FILE="$DOKKU_ROOT/$app/VHOST"
    local namespace="$(fn-plugin-property-get "scheduler-kubernetes" "$app" "namespace" "")"
    local cert_manager_enabled="$(fn-plugin-property-get "scheduler-kubernetes" "$app" "cert-manager-enabled" "")"

    if [[ "$APP_NAMESPACE" != "$namespace" ]]; then
      continue
    fi

    if [[ ! -f "$DOKKU_SCALE_FILE" ]] || [[ ! -f "$DOKKU_VHOST_FILE" ]]; then
      continue
    fi

    if [[ "$(plugn trigger proxy-type "$app")" != "nginx-ingress" ]]; then
      continue
    fi

    if [[ "$(is_app_vhost_enabled "$app")" == "false" ]]; then
      continue
    fi

    while read -r line || [[ -n "$line" ]]; do
      [[ "$line" =~ ^#.* ]] && continue
      line="$(strip_inline_comments "$line")"
      PROC_TYPE=${line%%=*}
      PROC_COUNT=${line#*=}

      if [[ "$PROC_TYPE" != "web" ]]; then
        continue
      fi

      while read -r DOMAIN || [[ -n "$DOMAIN" ]]; do
        if [[ "$cert_manager_enabled" == "true" ]]; then
          CERT_MANAGER_DOMAINS+=("$DOMAIN")
        fi

        HAS_RULE=true
        fn-scheduler-kubernetes-add-ingress-rule "$app" "$PROC_TYPE" "5000" "$DOMAIN" "$TMP_FILE"
      done <"$DOKKU_VHOST_FILE"
    done <"$DOKKU_SCALE_FILE"
  done

  if [[ "$HAS_RULE" == "false" ]]; then
    return
  fi

  local KUBE_ARGS=()
  if [[ -n "$APP_NAMESPACE" ]]; then
    KUBE_ARGS+=("--namespace=$APP_NAMESPACE")
    fn-scheduler-kubernetes-ensure-namespace "$APP_NAMESPACE" >/dev/null
  fi

  local SCHEME=http
  if [[ -n "$CERT_MANAGER_EMAIL" ]] && [[ -n "$CERT_MANAGER_DOMAINS" ]]; then
    local SCHEME=https
    fn-scheduler-kubernetes-add-cert-manager "$TMP_FILE" "${CERT_MANAGER_DOMAINS[@]}"
  fi

  plugn trigger pre-kubernetes-ingress-apply "$APP" "$TMP_FILE"
  "${DOKKU_LIB_ROOT}/data/scheduler-kubernetes/kubectl" "${KUBE_ARGS[@]}" apply -f "$TMP_FILE" | sed "s/^/       /"

  local URLS_PATH="$DOKKU_ROOT/$APP/URLS"
  local NONSSL_VHOSTS=$(get_app_domains "$APP")
  if [[ -n "$NONSSL_VHOSTS" ]]; then
    echo "# THIS FILE IS GENERATED BY DOKKU - DO NOT EDIT, YOUR CHANGES WILL BE OVERWRITTEN" >"$URLS_PATH"
    xargs -i echo "$SCHEME://{}" <<<"$(echo "${NONSSL_VHOSTS}" | tr ' ' '\n' | sort -u)" >>"$URLS_PATH"
  fi
}

fn-scheduler-kubernetes-ensure-namespace() {
  declare NAMESPACE="$1"
  local NAMESPACE_TEMPLATE="$PLUGIN_AVAILABLE_PATH/scheduler-kubernetes/templates/namespace.json.sigil"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  SIGIL_PARAMS=(NAME="$NAMESPACE")
  sigil -f "$NAMESPACE_TEMPLATE" "${SIGIL_PARAMS[@]}" | cat -s >$TMP_FILE

  "${DOKKU_LIB_ROOT}/data/scheduler-kubernetes/kubectl" apply -f "$TMP_FILE" | sed "s/^/       /"
}

fn-set-deployment-annotations() {
  declare APP="$1" DEPLOYMENT_FILE="$2"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  ANNOTATION_COUNT="$(fn-plugin-property-list-length "scheduler-kubernetes" "$APP" "deployment-annotations")"
  if [[ "$ANNOTATION_COUNT" == 0 ]]; then
    return
  fi

  jq -M --argjson data "{}" '.metadata.annotations += $data' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$DEPLOYMENT_FILE"

  while IFS="" read -r p || [ -n "$p" ]; do
    local KEY="$(echo "$p" | cut -d' ' -f1)"
    local VALUE="$(echo "$p" | cut -d' ' -f2)"
    KEY="$KEY" VALUE="$VALUE" jq -M '.metadata.annotations[env.KEY] = env.VALUE' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  done < <(fn-plugin-property-list-get "scheduler-kubernetes" "$APP" "deployment-annotations")
}

fn-set-env-vars() {
  declare APP="$1" DEPLOYMENT_FILE="$2"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  jq -M --argjson data "$(config_export app "$APP" --format json-list --merged)" '.spec.template.spec.containers[0].env += $data' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$DEPLOYMENT_FILE"
}

fn-set-healthchecks() {
  declare APP="$1" PROC_TYPE="$2" DEPLOYMENT_FILE="$3"
  local TMP_DIR=$(mktemp -d "/tmp/${FUNCNAME[0]}.XXXX")
  local APP_JSON_TMPL="$TMP_DIR/app.json.sigil"
  local APP_JSON_FILE="$TMP_DIR/app.json"
  local PROBE_FILE="$TMP_DIR/probe.json"
  local DEPLOYMENT_TMP_FILE="$TMP_DIR/deployment.json"
  trap 'rm -rf "$TMP_DIR" > /dev/null' RETURN INT TERM EXIT

  copy_from_image "$IMAGE" "app.json" "$APP_JSON_TMPL" 2>/dev/null || true

  if [[ ! -f "$APP_JSON_TMPL" ]]; then
    return 0
  fi

  # We use sigil templating to allow the health check configurations to refer
  # to the app name with the variable $APP.
  local SIGIL_PARAMS=(APP="$APP")
  sigil -f "$APP_JSON_TMPL" "${SIGIL_PARAMS[@]}" | cat -s >$APP_JSON_FILE

  for PROBE_TYPE in liveness readiness; do
    if jq -e -M ".healthchecks.\"$PROC_TYPE\".\"$PROBE_TYPE\"" <"$APP_JSON_FILE" >"$PROBE_FILE" \
      || jq -e -M ".healthchecks.\"*\".\"$PROBE_TYPE\"" <"$APP_JSON_FILE" >"$PROBE_FILE"; then
      jq -M --argjson data "$(cat "$PROBE_FILE")" ".spec.template.spec.containers[0].${PROBE_TYPE}Probe += \$data" <"$DEPLOYMENT_FILE" >"$DEPLOYMENT_TMP_FILE"
      mv "$DEPLOYMENT_TMP_FILE" "$DEPLOYMENT_FILE"
    fi
  done
}

fn-set-image-pull-secrets() {
  declare IMAGE_PULL_SECRETS="$1" DEPLOYMENT_FILE="$2"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  if [[ -n "$IMAGE_PULL_SECRETS" ]]; then
    IMAGE_PULL_SECRETS="$IMAGE_PULL_SECRETS" jq -M ".spec.template.spec.imagePullSecrets[0].name = env.IMAGE_PULL_SECRETS" <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  fi
}

fn-set-pod-annotations() {
  declare APP="$1" DEPLOYMENT_FILE="$2"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  ANNOTATION_COUNT="$(fn-plugin-property-list-length "scheduler-kubernetes" "$APP" "pod-annotations")"
  if [[ "$ANNOTATION_COUNT" == 0 ]]; then
    return
  fi

  jq -M --argjson data "{}" '.spec.template.metadata.annotations += $data' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$DEPLOYMENT_FILE"

  while IFS="" read -r p || [ -n "$p" ]; do
    local KEY="$(echo "$p" | cut -d' ' -f1)"
    local VALUE="$(echo "$p" | cut -d' ' -f2)"
    KEY="$KEY" VALUE="$VALUE" jq -M '.spec.template.metadata.annotations[env.KEY] = env.VALUE' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  done < <(fn-plugin-property-list-get "scheduler-kubernetes" "$APP" "pod-annotations")
}

fn-set-ports() {
  declare APP="$1" DEPLOYMENT_FILE="$2"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  if is_image_herokuish_based "$IMAGE"; then
    jq -M --argjson data "[{\"name\": \"PORT\", \"value\": \"5000\"}]" '.spec.template.spec.containers[0].env += $data' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  fi
}

fn-set-pod-disruption-constraints() {
  declare APP="$1"
  local POD_TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  MIN_AVAILABLE="$(fn-plugin-property-get "scheduler-kubernetes" "$APP" "pod-min-available" "")"
  MAX_UNAVAILABLE="$(fn-plugin-property-get "scheduler-kubernetes" "$APP" "pod-max-unavailable" "")"

  if [[ -z "$MIN_AVAILABLE" ]] && [[ -z "$MAX_UNAVAILABLE" ]]; then
    return
  fi

  export KUBECONFIG="${DOKKU_ROOT}/.kube/config"
  KUBE_ARGS=()
  NAMESPACE="$(fn-plugin-property-get "scheduler-kubernetes" "$APP" "namespace" "")"
  if [[ -n "$NAMESPACE" ]]; then
    KUBE_ARGS+=("--namespace=$NAMESPACE")
    fn-scheduler-kubernetes-ensure-namespace "$NAMESPACE" >/dev/null
  fi

  local SIGIL_PARAMS=(APP="$APP")
  sigil -f "$DEPLOYMENT_TEMPLATE" "${SIGIL_PARAMS[@]}" | cat -s >$POD_TMP_FILE

  if [[ -n "$MIN_AVAILABLE" ]]; then
    MIN_AVAILABLE="$MIN_AVAILABLE" jq -M '.spec.minAvailable = (env.MIN_AVAILABLE|tonumber)' <"$POD_TMP_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$POD_TMP_FILE"
  fi

  if [[ -n "$MAX_UNAVAILABLE" ]]; then
    MAX_UNAVAILABLE="$MAX_UNAVAILABLE" jq -M '.spec.maxUnavailable = (env.MAX_UNAVAILABLE|tonumber)' <"$POD_TMP_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$POD_TMP_FILE"
  fi

  dokku_log_info1 "Creating PodDisruptionBudget for ${APP}"
  "${DOKKU_LIB_ROOT}/data/scheduler-kubernetes/kubectl" "${KUBE_ARGS[@]}" apply -f "$POD_TMP_FILE" | sed "s/^/       /"
}

fn-set-resource-constraints() {
  declare APP="$1" PROC_TYPE="$2" DEPLOYMENT_FILE="$3"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  RESOURCE_LIMITS_CPU=$(plugn trigger resource-get-property "$APP" "$PROC_TYPE" "limit" "cpu" 2>/dev/null || true)
  RESOURCE_LIMITS_NVIDIA_GPU=$(plugn trigger resource-get-property "$APP" "$PROC_TYPE" "limit" "nvidia-gpu" 2>/dev/null || true)
  RESOURCE_LIMITS_MEMORY=$(plugn trigger resource-get-property "$APP" "$PROC_TYPE" "limit" "memory" 2>/dev/null || true)
  RESOURCE_REQUESTS_CPU=$(plugn trigger resource-get-property "$APP" "$PROC_TYPE" "reserve" "cpu" 2>/dev/null || true)
  RESOURCE_REQUESTS_MEMORY=$(plugn trigger resource-get-property "$APP" "$PROC_TYPE" "reserve" "memory" 2>/dev/null || true)

  if [[ -n "$RESOURCE_LIMITS_CPU" ]]; then
    RESOURCE_LIMITS_CPU="$RESOURCE_LIMITS_CPU" jq -M ".spec.template.spec.containers[0].resources.limits.cpu = env.RESOURCE_LIMITS_CPU" <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  fi

  if [[ -n "$RESOURCE_LIMITS_NVIDIA_GPU" ]] && [[ "$RESOURCE_LIMITS_NVIDIA_GPU" != "0" ]]; then
    re='^[0-9]+$'
    if [[ "$RESOURCE_LIMITS_NVIDIA_GPU" =~ $re ]]; then
      RESOURCE_LIMITS_NVIDIA_GPU="$RESOURCE_LIMITS_NVIDIA_GPU" jq -M '.spec.template.spec.containers[0].resources.limits["nvidia.com/gpu"] = (env.RESOURCE_LIMITS_NVIDIA_GPU|tonumber)' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    else
      RESOURCE_LIMITS_NVIDIA_GPU="$RESOURCE_LIMITS_NVIDIA_GPU" jq -M '.spec.template.spec.containers[0].resources.limits["nvidia.com/gpu"] = env.RESOURCE_LIMITS_NVIDIA_GPU' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    fi
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  fi

  if [[ -n "$RESOURCE_LIMITS_MEMORY" ]]; then
    RESOURCE_LIMITS_MEMORY="$RESOURCE_LIMITS_MEMORY" jq -M ".spec.template.spec.containers[0].resources.limits.memory = env.RESOURCE_LIMITS_MEMORY" <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  fi

  if [[ -n "$RESOURCE_REQUESTS_CPU" ]]; then
    RESOURCE_REQUESTS_CPU="$RESOURCE_REQUESTS_CPU" jq -M ".spec.template.spec.containers[0].resources.requests.cpu = env.RESOURCE_REQUESTS_CPU" <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  fi

  if [[ -n "$RESOURCE_REQUESTS_MEMORY" ]]; then
    RESOURCE_REQUESTS_MEMORY="$RESOURCE_REQUESTS_MEMORY" jq -M ".spec.template.spec.containers[0].resources.requests.memory = env.RESOURCE_REQUESTS_MEMORY" <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  fi
}

fn-set-service-annotations() {
  declare APP="$1" DEPLOYMENT_FILE="$2"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")
  trap 'rm -rf "$TMP_FILE" > /dev/null' RETURN INT TERM EXIT

  ANNOTATION_COUNT="$(fn-plugin-property-list-length "scheduler-kubernetes" "$APP" "service-annotations")"
  if [[ "$ANNOTATION_COUNT" == 0 ]]; then
    return
  fi

  jq -M --argjson data "{}" '.metadata.annotations += $data' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$DEPLOYMENT_FILE"

  while IFS="" read -r p || [ -n "$p" ]; do
    local KEY="$(echo "$p" | cut -d' ' -f1)"
    local VALUE="$(echo "$p" | cut -d' ' -f2)"
    KEY="$KEY" VALUE="$VALUE" jq -M '.metadata.annotations[env.KEY] = env.VALUE' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
    mv "$TMP_FILE" "$DEPLOYMENT_FILE"
  done < <(fn-plugin-property-list-get "scheduler-kubernetes" "$APP" "service-annotations")
}

fn-strip-ports() {
  declare DEPLOYMENT_FILE="$1"
  local TMP_FILE=$(mktemp "/tmp/${FUNCNAME[0]}.XXXX")

  jq -M 'del(.spec.template.spec.containers[0].ports)' <"$DEPLOYMENT_FILE" >"$TMP_FILE"
  mv "$TMP_FILE" "$DEPLOYMENT_FILE"
}
